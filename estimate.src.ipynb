{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "layout": {
       "col": 0,
       "height": 5,
       "row": 0,
       "width": 12
      }
     }
    }
   },
   "source": [
    "# Estimate of Public Jupyter Notebooks on GitHub\n",
    "\n",
    "This notebook shows the historical count and future estimate of the number of `*.ipynb` files on GitHub. The daily count comes from executing the query [extension:ipynb nbformat_minor](https://github.com/search?utf8=%E2%9C%93&q=extension%3Aipynb+nbformat_minor) once a day, on most days. We re-render the notebook and publish it daily after the update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "layout": {
       "col": 0,
       "height": 9,
       "row": 5,
       "width": 12
      }
     }
    }
   },
   "source": [
    "## Assumptions\n",
    "\n",
    "1. That the search query hits and notebooks on GitHub are in 1:1 correspondence.\n",
    "1. That GitHub is accurately reporting the total number of `*.ipynb` file hits.\n",
    "1. That the result is **not** inflated due to GitHub forks.\n",
    "    * Evidence: We do not see the tutorial notebooks from the ipython/ipython GitHub repository duplicated in the search results because of the 2,000+ forks of the ipython/ipython repo.\n",
    "1. That the result **is** inflated a tiny bit by manually created duplicates of notebooks.\n",
    "    * Evidence: Some people seem to download their favorite notebooks and then upload them into their own git repositories for safe keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "mpl.style.use('ggplot')\n",
    "figsize = (14,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.utcnow()\n",
    "print(f'This notebook was last rendered at {now} UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "## Raw Hits\n",
    "\n",
    "First, let's load the historical data into a DataFrame indexed by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "hits_df = pd.read_csv('ipynb_counts.csv', index_col=0, header=0, parse_dates=True)\n",
    "hits_df.reset_index(inplace=True)\n",
    "hits_df.drop_duplicates(subset='date', inplace=True)\n",
    "hits_df.set_index('date', inplace=True)\n",
    "hits_df.sort_index(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "outputs": [],
   "source": [
    "hits_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "There might be missing counts for days that we failed to sample. We build up the expected date range and insert NaNs for dates we missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "til_today = pd.date_range(hits_df.index[0], hits_df.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "hits_df = hits_df.reindex(til_today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "Now we plot the known notebook counts for each day we've been tracking the query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "urth": {
     "dashboard": {
      "layout": {
       "col": 0,
       "height": 18,
       "row": 14,
       "width": 12
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "ax = hits_df.plot(title=f\"GitHub search hits for {len(hits_df)} days\", figsize=figsize)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('# of ipynb files');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothed Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "We don't have data for every day in the collection timeframe. We'll use simple linear interpolation to fill the gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "daily_deltas = (hits_df.hits - hits_df.hits.shift()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "hits_df = hits_df.interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "outputs": [],
   "source": [
    "ax = hits_df.plot(title=f\"GitHub search hits for {len(hits_df)} days sans outliers\", \n",
    "                  figsize=figsize)\n",
    "ax.set_xlabel('Date')\n",
    "_ = ax.set_ylabel('# of ipynb files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "The total change in the number of `*.ipynb` hits between the tracking start date and today is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "outputs": [],
   "source": [
    "total_delta_nbs = hits_df.iloc[-1] - hits_df.iloc[0]\n",
    "total_delta_nbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "The daily average change for the entire duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "outputs": [],
   "source": [
    "avg_delta_nbs = total_delta_nbs / len(hits_df)\n",
    "avg_delta_nbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "We can look at the daily change over the entire period alongside the rolling 30-day mean of the daily deltas.\n",
    "\n",
    "The large jumps in the data are from GitHub reporting drastically different counts from one day to the next. We suspect this happens when they rebuild their search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "daily_deltas = (hits_df.hits - hits_df.hits.shift()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.plot(daily_deltas.rolling(window=30, min_periods=0, center=False).mean(), \n",
    "        label='30-day rolling mean of daily-change')\n",
    "ax.plot(daily_deltas, label='24-hour change')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Delta notebook count')\n",
    "ax.set_title('Change in notebook count')\n",
    "_ = ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the rolling mean in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.plot(daily_deltas.rolling(window=30, min_periods=0, center=False).mean())\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Delta notebook count')\n",
    "_ = ax.set_title('30-day rolling mean of daily-change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "render": false,
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "## Count Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "render": false,
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "We next train an [autoregressive model](http://en.wikipedia.org/wiki/Autoregressive_model) on the prior year of data. We then use the model to predict the number of notebooks on GitHub a year from now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = datetime.timedelta(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "train_df = hits_df.loc[now.date()-delta:]\n",
    "model = sm.tsa.AR(train_df, freq='D').fit(ic='aic')\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict counts through a full year in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "pred_s = model.predict(\n",
    "    (now.date()-delta + datetime.timedelta(model.k_ar)).strftime('%Y-%m-%d'),\n",
    "    (now.date()+delta).strftime('%Y-%m-%d'),\n",
    "    dynamic=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the truth and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {
      "layout": {
       "col": 0,
       "height": 16,
       "row": 49,
       "width": 12
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_title(f'GitHub search hits predicted until {now.date()+delta}')\n",
    "# plot the raw search numbers\n",
    "ax.plot(hits_df, 'ko', markersize=1, label='truth')\n",
    "# use the pandas plotting api mostly because it formats the legend for us\n",
    "ax.plot(pred_s, linewidth=2, label='predicted')\n",
    "# show labels\n",
    "ax.legend()\n",
    "_ = ax.set_ylabel('# of ipynb files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "We plot the residuals to get a sense of how well the model matches recent observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pred_s.to_frame(name='predicted')\n",
    "eval_df['truth'] = hits_df.hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "residual_df = eval_df.subtract(eval_df.truth, axis=0).dropna().drop('truth', axis=1)\n",
    "_ = eval_df.drop('truth', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "urth": {
     "dashboard": {
      "layout": {
       "col": 0,
       "height": 15,
       "row": 65,
       "width": 12
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ret = ax.plot(residual_df, 'o', ms=2)\n",
    "ax.set_ylabel('# predicted hits - # true hits')\n",
    "ax.set_title('Residuals')\n",
    "fig.autofmt_xdate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "urth": {
   "dashboard": {
    "cellMargin": 10,
    "defaultCellHeight": 20,
    "layoutStrategy": "packed",
    "maxColumns": 12
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
